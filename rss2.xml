<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>永远的万事屋</title>
    <link>http://yoursite.com/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>做海贼王的油腻男人</description>
    <pubDate>Wed, 25 Sep 2019 12:05:12 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>HashMap的小认识</title>
      <link>http://yoursite.com/2019/09/23/2019-9/HashMap%E7%9A%84%E5%B0%8F%E8%AE%A4%E8%AF%86/</link>
      <guid>http://yoursite.com/2019/09/23/2019-9/HashMap%E7%9A%84%E5%B0%8F%E8%AE%A4%E8%AF%86/</guid>
      <pubDate>Mon, 23 Sep 2019 10:21:36 GMT</pubDate>
      <description>
      
        &lt;p&gt;想充分了解HashMap很久了，这个我们时刻使用，但是对于我来说总感觉有着迷雾的数据结构。  &lt;/p&gt;
&lt;p&gt;##HashMap&lt;br&gt;下面是居于JDK7的，JDK8的红黑树结构暂时放弃。  &lt;/p&gt;
&lt;h3 id=&quot;数据结构&quot;&gt;&lt;a href=&quot;#数据结构&quot; class=&quot;headerlink&quot; title=&quot;数据结构&quot;&gt;&lt;/a&gt;数据结构&lt;/h3&gt;&lt;p&gt;HashMap继承了AbstractMap、实现了Map&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class HashMap&amp;lt;K,V&amp;gt;
extends AbstractMap&amp;lt;K,V&amp;gt;
implements Map&amp;lt;K,V&amp;gt;, Cloneable, Serializable
{
/**
 * The table, resized as necessary. Length MUST Always be a power of two.
 */
transient Entry&amp;lt;K,V&amp;gt;[] table;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重要的是数组table以及它的内部类Entry。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static class Entry&amp;lt;K,V&amp;gt; implements Map.Entry&amp;lt;K,V&amp;gt; {
    final K key;
    V value;
    Entry&amp;lt;K,V&amp;gt; next;
    int hash;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到Entry里有一个next属性，所以它本身就是个单链表，以下就是我们常说的数组+链表的结构：  &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/4843132-05b3a55bd2686dd3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>想充分了解HashMap很久了，这个我们时刻使用，但是对于我来说总感觉有着迷雾的数据结构。  </p><p>##HashMap<br>下面是居于JDK7的，JDK8的红黑树结构暂时放弃。  </p><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>HashMap继承了AbstractMap、实现了Map</p><pre><code>public class HashMap&lt;K,V&gt;extends AbstractMap&lt;K,V&gt;implements Map&lt;K,V&gt;, Cloneable, Serializable{/** * The table, resized as necessary. Length MUST Always be a power of two. */transient Entry&lt;K,V&gt;[] table;</code></pre><p>重要的是数组table以及它的内部类Entry。  </p><pre><code>static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {    final K key;    V value;    Entry&lt;K,V&gt; next;    int hash;</code></pre><p>可以看到Entry里有一个next属性，所以它本身就是个单链表，以下就是我们常说的数组+链表的结构：  </p><p><img src="https://upload-images.jianshu.io/upload_images/4843132-05b3a55bd2686dd3.png" alt=""></p><a id="more"></a><h3 id="put方法"><a href="#put方法" class="headerlink" title="put方法"></a>put方法</h3><p>代码还是很简单的，稍微一看都能清楚：  </p><pre><code>public V put(K key, V value) {       // 对key为null的处理       if (key == null)           return putForNullKey(value);       // 根据key算出hash值       int hash = hash(key);       // 根据hash值和HashMap容量算出在table中应该存储的下标i       int i = indexFor(hash, table.length);       for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) {           Object k;           // 先判断hash值是否一样，如果一样，再判断key是否一样           if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) {               V oldValue = e.value;               e.value = value;               e.recordAccess(this);               return oldValue;           }       }       modCount++;       addEntry(hash, key, value, i);       return null;   }</code></pre><p>整理出来的流程图如下：<br><img src="https://upload-images.jianshu.io/upload_images/4843132-3d5e78f87bb64216.png" alt=""><br>值得注意点的地方是：   </p><pre><code>static int indexFor(int h, int length) {    return h &amp; (length-1);}</code></pre><p>可以看到是用&amp;的位运算，&amp;运算是CPU的运算方式，所以效率是杠杠的，至于为什么是跟length-1进行&amp;的位运呢？<br>因为length为2的幂次方，即一定是偶数，偶数减1，即是奇数，这样保证了（length-1）在二进制中最低位是1，而&amp;运算结果的最低位是1还是0完全取决于hash值二进制的最低位。如果length为奇数，则length-1则为偶数，则length-1二进制的最低位横为0，则&amp;位运算的结果最低位横为0，即横为偶数。这样table数组就只可能在偶数下标的位置存储了数据，浪费了所有奇数下标的位置，这样也更容易产生hash冲突。<strong>这也是HashMap的容量为什么总是2的平方数的原因。</strong><br><img src="https://upload-images.jianshu.io/upload_images/4843132-91b165309b5d447c.png" alt=""></p><h3 id="resize、get"><a href="#resize、get" class="headerlink" title="resize、get"></a>resize、get</h3><p>这个的流程和put类似，都是先计算hash值以及对应的index下表，然后重新赋值或者获取元素，这里就不在啰嗦。</p><h3 id="iterate"><a href="#iterate" class="headerlink" title="iterate"></a>iterate</h3><p>这里我了解下，为什么map的遍历不是有序的，以及它是如何做的。<br>核心代码如下：  </p><pre><code>final Entry&lt;K,V&gt; nextEntry() {    // 保存下一个需要返回的Entry，作为返回结果    Entry&lt;K,V&gt; e = next;    // 如果遍历到table上单向链表的最后一个元素时    if ((next = e.next) == null) {        Entry[] t = table;        // 继续往下寻找table上有元素的下标        // 并且把下一个talbe上有单向链表的表头，作为下一个返回的Entry next        while (index &lt; t.length &amp;&amp; (next = t[index++]) == null)            ;    }    current = e;    return e;}</code></pre><p>nextEntry的主要作用有两点</p><ol><li>把当前遍历到的Entry返回</li><li>准备好下一个需要返回的Entry  </li></ol><p>如果当前返回的Entry不是单向链表的最后一个元素，那只要让下一个返回的Entrynext为当前Entry的next属性（下图红色过程）；如果当前返回的Entry是单向链表的最后一个元素，那么它就没有next属性了，所以要寻找下一个table上有单向链表的表头（下图绿色过程）<br><img src="https://upload-images.jianshu.io/upload_images/4843132-3830a9227f7df10f.png" alt="">  </p><p>##LinkedHashMap<br>LinkedHashMap是在HashMap的基础上又维护了Entry之间的一个双向链表，其结构如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/4843132-7abca1abd714341d.png" alt="">  </p><pre><code>private static class Entry&lt;K,V&gt; extends HashMap.Entry&lt;K,V&gt; {    // These fields comprise the doubly linked list used for iteration.    Entry&lt;K,V&gt; before, after;    Entry(int hash, K key, V value, HashMap.Entry&lt;K,V&gt; next) {        super(hash, key, value, next);    }</code></pre><p>可以到相比HashMap.Entry，LinkedHashMap.Entry多了before和after，这就是用来维护双向链表的。</p><h3 id="put方法-1"><a href="#put方法-1" class="headerlink" title="put方法"></a>put方法</h3><p>新加入的元素维护到双向链表的末尾，代码如下：  </p><pre><code>private void addBefore(Entry&lt;K,V&gt; existingEntry) {    after  = existingEntry;    before = existingEntry.before;    before.after = this;    after.before = this;}</code></pre><h3 id="iterate-1"><a href="#iterate-1" class="headerlink" title="iterate"></a>iterate</h3><p>从双向链表表头的第一个元素开始，遍历效率是大于HashMap的。</p><h3 id="重排序"><a href="#重排序" class="headerlink" title="重排序"></a>重排序</h3><p>LinkedHashMap有一个比较特殊的构造函数：  </p><pre><code>public LinkedHashMap(int initialCapacity,                     float loadFactor,                     boolean accessOrder) {    super(initialCapacity, loadFactor);    this.accessOrder = accessOrder;}</code></pre><p>accessOrder默认为false，标识元素顺序与插入顺序相关；如果为true，标识元素顺序与访问顺序相关。能做到这点，就是因为在accessOrder=true的情况下，每一次访问都会将元素重新排序：  </p><pre><code>void recordAccess(HashMap&lt;K,V&gt; m) {    LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m;    // 如果LinkedHashMap的accessOrder为true，则进行重排序    // 比如前面提到LruCache中使用到的LinkedHashMap的accessOrder属性就为true    if (lm.accessOrder) {        lm.modCount++;        // 把更新的Entry从双向链表中移除        remove();        // 再把更新的Entry加入到双向链表的表尾        addBefore(lm.header);    }}</code></pre><p>其实到这里我就比较好奇了，根据插入顺序的HashMap还有一些场景，但是每次读顺序都会改变的HashMap有哪些使用场景呢？</p><!-- more --><h2 id="LinkedHashMap与LRU"><a href="#LinkedHashMap与LRU" class="headerlink" title="LinkedHashMap与LRU"></a>LinkedHashMap与LRU</h2><p>每次访问的元素都会被放置在队列末尾，这和LRU（Least Recently Used最近最少算法）算法的特性是一致的。所以我们利用这个特性，能很轻易实现LRU-1算法，事实上java本身也给我们留好了实现的接口：  </p><pre><code>protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) {    return false;}</code></pre><p>我们只要覆盖这个方法就是一个线程不安全的LRU了。<br>LRU本身是内存淘汰算法，关于这个请听下回分解。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/09/23/2019-9/HashMap%E7%9A%84%E5%B0%8F%E8%AE%A4%E8%AF%86/#disqus_thread</comments>
    </item>
    
    <item>
      <title>parallelStream注意点</title>
      <link>http://yoursite.com/2019/04/11/2019-4/parallelStream%20null/</link>
      <guid>http://yoursite.com/2019/04/11/2019-4/parallelStream%20null/</guid>
      <pubDate>Thu, 11 Apr 2019 09:22:36 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;刚刚的项目中发现了一个bug，是由于使用parallelStream导致，在此记录下。  &lt;/p&gt;
&lt;h3 id=&quot;现象&quot;&gt;&lt;a href=&quot;#现象&quot; class=&quot;headerlink&quot; title=&quot;现象&quot;&gt;&lt;/a&gt;现象&lt;/h3&gt;&lt;p&gt;测试反馈，查询出来的数据不正确，有
        
      
      </description>
      
      <content:encoded><![CDATA[<p>刚刚的项目中发现了一个bug，是由于使用parallelStream导致，在此记录下。  </p><h3 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h3><p>测试反馈，查询出来的数据不正确，有时候多一个有时候少一个。</p><h3 id="定位问题"><a href="#定位问题" class="headerlink" title="定位问题"></a>定位问题</h3><p>由此看来这肯定是一个比较让人困惑的问题，而能想到的这种随机性问题基本都和并发有关。所以我就想到了，我在一个循环rpc的中使用了parallelStream，如下所示：<br><img src="https://i.imgur.com/9tBLlMa.png" alt=""></p><h3 id="解惑答疑"><a href="#解惑答疑" class="headerlink" title="解惑答疑"></a>解惑答疑</h3><p>使用parallelStream只考虑到了ForkJoinPool最终会等待每个线程执行完毕，但是并没有考虑到线程安全问题，最终返回的结果就导致了list列表里出现了null。更深层次原因是由于ArrayList.add方法并不是线程安全的，如下所示：<br><img src="https://i.imgur.com/P8Vg2D5.png" alt=""><br>是先增加了容器大小，然后再赋值，这个操作并不是一个原子操作，导致了此问题。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/04/11/2019-4/parallelStream%20null/#disqus_thread</comments>
    </item>
    
    <item>
      <title>jvm的意义</title>
      <link>http://yoursite.com/2019/01/29/2019-1/jvm%E7%9A%84%E5%B0%8F%E7%90%86%E8%A7%A3/</link>
      <guid>http://yoursite.com/2019/01/29/2019-1/jvm%E7%9A%84%E5%B0%8F%E7%90%86%E8%A7%A3/</guid>
      <pubDate>Tue, 29 Jan 2019 08:01:12 GMT</pubDate>
      <description>
      
        &lt;p&gt;哈哈哈，请原谅我标题的假大空，其实我想说只有两点：  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;为什么会出现jvm这种技术以及jvm是如何发展到今天的？  &lt;/li&gt;
&lt;li&gt;什么才是jvm当下最大的优势？  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在大约20多年前，当时主流的开发语言还是C，C语言由于其编译后直接运行在操作系统之上，被称为运行最快的语言。但这也带来了开发人员的苦恼，开发人员不得不去了解各个操作系统的差异性，来编写出适应于某个操作系统的代码。  &lt;/p&gt;
&lt;p&gt;在1995年SunWorld大会上，首次提出“Write Once, Run Anywhere”的口号，而那时候windows95几个月后在正式发布，linix 1.0版也才发布一年，可以想象在那个时候挺具有的划时代意义的。时间回到现在，windows系统在服务器端越来走下坡路，而linux几乎是势不可挡（至少在互联网领域），在这种现状下，所谓的“Write Once, Run Anywhere”是否真的还是jvm的决对优势呢？其实我们简单思考下就可以了，想想我们在我们的司龄内是否有更换服务器环境的需求呢？  &lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>哈哈哈，请原谅我标题的假大空，其实我想说只有两点：  </p><ol><li>为什么会出现jvm这种技术以及jvm是如何发展到今天的？  </li><li>什么才是jvm当下最大的优势？  </li></ol><p>在大约20多年前，当时主流的开发语言还是C，C语言由于其编译后直接运行在操作系统之上，被称为运行最快的语言。但这也带来了开发人员的苦恼，开发人员不得不去了解各个操作系统的差异性，来编写出适应于某个操作系统的代码。  </p><p>在1995年SunWorld大会上，首次提出“Write Once, Run Anywhere”的口号，而那时候windows95几个月后在正式发布，linix 1.0版也才发布一年，可以想象在那个时候挺具有的划时代意义的。时间回到现在，windows系统在服务器端越来走下坡路，而linux几乎是势不可挡（至少在互联网领域），在这种现状下，所谓的“Write Once, Run Anywhere”是否真的还是jvm的决对优势呢？其实我们简单思考下就可以了，想想我们在我们的司龄内是否有更换服务器环境的需求呢？  </p><a id="more"></a><p>所以我们可能都被误导了，jvm能发展20年到今日还如此活跃，绝不仅仅因为其当时倡导的平台无关性的。我们思考下近些年比较火的一些语言，无论是php、python甚至kotlin、go，都有一个普遍的特点就是简单、易懂。我们视线回到jvm本身上，jvm本身的优势也是一样的。C语言开发者需要关心内存分配、对象回收甚至线程管理，而这些不正是jvm所做的事情吗？解放了程序员的生产力，程序员只需要关心其代码，和操作系统、内存打交道的事情都由jvm去处理了。再思考下我们现在所用的一些框架（例如spring），又进一步解放了程序员的生产力，程序员只需要关心业务逻辑了。  </p><p>有很多的人，总是唱衰现在的开发人员，尊崇老一辈的程序员，甚至还有了所谓的开发语言鄙视链，理由<br>无非是“不懂底层实现”等等。从个人的角度来说，现在的开发人员这方面确实相对比老一辈的人员懂的少一些，但现在的程序员所涉及到的知识储备可能也是原来比不了的。这个其实可能也归因于，我们的生产力的解放，然后才能把以精力投入到其他方面。从整个互联网的发展来说，这个无疑是进步的，人类的发展表现在工作的细分，从这个角度来说，我们可以说是进步了吧。(●’◡’●)  </p><p>说一下我的思考历程，最开始想到了java编译器，然后找到了jvm的解释器（原来了解到java其实是一门解释型语言），然后想到了平台无关性，然后思考平台无关性存在的意义，到此引发上文end。  </p><p>马上过年了，祝自己新年快乐。(●’◡’●)  </p>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/01/29/2019-1/jvm%E7%9A%84%E5%B0%8F%E7%90%86%E8%A7%A3/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CAP的小理解</title>
      <link>http://yoursite.com/2019/01/08/2019-1/CAP/</link>
      <guid>http://yoursite.com/2019/01/08/2019-1/CAP/</guid>
      <pubDate>Tue, 08 Jan 2019 08:22:36 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;最近罗胖的“小趋势”很火，这里我也蹭蹭热度，来一个“小理解”。  &lt;/p&gt;
&lt;h3 id=&quot;先聊聊分布式&quot;&gt;&lt;a href=&quot;#先聊聊分布式&quot; class=&quot;headerlink&quot; title=&quot;先聊聊分布式&quot;&gt;&lt;/a&gt;先聊聊分布式&lt;/h3&gt;&lt;p&gt;其实对于分布式我原来一直是
        
      
      </description>
      
      <content:encoded><![CDATA[<p>最近罗胖的“小趋势”很火，这里我也蹭蹭热度，来一个“小理解”。  </p><h3 id="先聊聊分布式"><a href="#先聊聊分布式" class="headerlink" title="先聊聊分布式"></a>先聊聊分布式</h3><p>其实对于分布式我原来一直是有些疑问的，是关于一致性的，一致性是分布式系统面临的问题，但一个系统如果没有一致性问题，那这个系统到底算不算分布式系统呢？比如说，最简单情况，一个电商系统，是由商品、交易、订单组成的，就是说我完成一个下单，需要调用这些个系统，但是这些系统都是使用的同一个DB，换句话说就是，系统层面进行了切分，但是资源是同一个。发现没有，这些系统之间有rpc、mq，甚至进行了分区（不同地区的机房）。到这里不要疑惑，我们每天接触的绝对是分布式系统，只不过它面临CAP问题只解决了C，AP问题仍在。当它想要区解决AP问题的时候，就会发现C不能保证了，这就是著名的CAP定理。</p><h3 id="我的小疑惑"><a href="#我的小疑惑" class="headerlink" title="我的小疑惑"></a>我的小疑惑</h3><p>关于CAP的解释我这里就不再赘述了，我这里只想聊聊CAP中的“P”。好多文章里都翻译成了“分区容忍”，可能是我的理解能力有问题？总是对这个概念不能很清晰的理解。今天看到阮一峰老师的文章，将P翻译成“分区容错”，有点醍醐灌顶的感觉，容错代表容许错误，这时候已经发生了错误。<br>大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（partition）。分区错误就是，区间通信失败。我们清楚，网络是不可信的，所以分区错误肯定会发生。对于分区错误，最常见的解决办法是Replication，这样即使分区之间发生了异常，有会有其他的节点提供服务，增强了可用性，但是这样又会带来一致性问题。所以，也传说着这样一句话，<strong>P（分区容错）是一定要保证的</strong>（虽然绝大多数根本做不到(●’◡’●)）。  </p><h3 id="解惑"><a href="#解惑" class="headerlink" title="解惑"></a>解惑</h3><p>然后我们思考下P的重要性，试思考下，如果不分区，可能会出现什么问题？很明显，如果发生任何外部因素，例如断电、电缆断掉等等，将导致你的系统不可用，这对于互联网行业来说是不能容忍的。在此基础上我们再考虑CA的问题。认真推导就会发现，<strong>在P的情况下，CA不可能同时保证</strong>。<br>然后我们聊聊关系型数据库，很多的文章都会说关系型数据库是CA模型，在大数据的情况下，关系型数据库面临最大的问题是扩展问题，扩展成多库存储，必然导致CA问题，而我们也清楚，分布式事务是很头疼的，而且至今也没有完美的解决方案。<br>推荐两篇不错的文章，<a href="https://www.jdon.com/bigdata/how-to-understand-cap.html" target="_blank" rel="noopener">https://www.jdon.com/bigdata/how-to-understand-cap.html</a>，<a href="http://www.ruanyifeng.com/blog/2018/07/cap.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2018/07/cap.html</a></p>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/01/08/2019-1/CAP/#disqus_thread</comments>
    </item>
    
    <item>
      <title>mysql lock</title>
      <link>http://yoursite.com/2018/09/30/2018-9/mysql%20lock/</link>
      <guid>http://yoursite.com/2018/09/30/2018-9/mysql%20lock/</guid>
      <pubDate>Sun, 30 Sep 2018 09:01:36 GMT</pubDate>
      <description>
      
        &lt;h3 id=&quot;锁级别&quot;&gt;&lt;a href=&quot;#锁级别&quot; class=&quot;headerlink&quot; title=&quot;锁级别&quot;&gt;&lt;/a&gt;锁级别&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;表级锁&lt;br&gt;表级锁的开销小，加锁快，不会出现死锁，锁定粒度大，大概率发生锁的冲突，并发度低。&lt;/li&gt;
&lt;li&gt;行级锁&lt;br&gt;行级锁的开销大，加锁满，会出现死锁，锁定粒度小，小概率发生锁的重读，并发度高。&lt;/li&gt;
&lt;li&gt;页级锁&lt;br&gt;支持页级锁的BDB引擎已经逐渐被InnoDB替代了，这里暂不讨论。  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上述特点来看，很难说哪种锁更好，只能相对于所处的业务场景来选择更加适合的锁机制。如果仅从锁的角度来看，表级锁更适合以查询为主的应用场景，而行级锁则更适合于大量按索引条件并发更新少量数据的应用场景。&lt;/p&gt;
&lt;h3 id=&quot;锁模式&quot;&gt;&lt;a href=&quot;#锁模式&quot; class=&quot;headerlink&quot; title=&quot;锁模式&quot;&gt;&lt;/a&gt;锁模式&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;共享锁(S)&lt;br&gt;共享锁是他人可以读但不能写&lt;/li&gt;
&lt;li&gt;排他锁(X)&lt;br&gt;排它锁则会阻塞他人的读写操作&lt;/li&gt;
&lt;/ol&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h3 id="锁级别"><a href="#锁级别" class="headerlink" title="锁级别"></a>锁级别</h3><ol><li>表级锁<br>表级锁的开销小，加锁快，不会出现死锁，锁定粒度大，大概率发生锁的冲突，并发度低。</li><li>行级锁<br>行级锁的开销大，加锁满，会出现死锁，锁定粒度小，小概率发生锁的重读，并发度高。</li><li>页级锁<br>支持页级锁的BDB引擎已经逐渐被InnoDB替代了，这里暂不讨论。  </li></ol><p>上述特点来看，很难说哪种锁更好，只能相对于所处的业务场景来选择更加适合的锁机制。如果仅从锁的角度来看，表级锁更适合以查询为主的应用场景，而行级锁则更适合于大量按索引条件并发更新少量数据的应用场景。</p><h3 id="锁模式"><a href="#锁模式" class="headerlink" title="锁模式"></a>锁模式</h3><ol><li>共享锁(S)<br>共享锁是他人可以读但不能写</li><li>排他锁(X)<br>排它锁则会阻塞他人的读写操作</li></ol><a id="more"></a><p>为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的<strong>意向锁</strong>（Intention Locks），这两种意向锁都是表锁。<br>意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。<br>意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。<br>上述来看，InnoDB为了实现多粒度锁机制，采用了意向锁。话句话说如果不将表级锁和行级锁有所区别的话，是实现不了多粒度锁机制的。所以我认为意向锁是为了实现锁的层级而发明出来的一种锁。  </p><h4 id="意向锁的作用"><a href="#意向锁的作用" class="headerlink" title="意向锁的作用"></a>意向锁的作用</h4><p>引进意向锁是为了提高封锁子系统的效率。意向锁的含义是：对任一结点加锁时，必须先对它的上层结点加意向锁。引进意向锁后，系统对某一数据对象加锁时不必逐个检查与下一级结点的封锁冲突了。  </p><p>这里说说我的看法，我们平时更新某一条数据，肯定会加一个表的IS锁，然后再对这一行加一个行级排他锁。在互联网中并发更新是最常见的场景，这个时候InnoDB是如何判断有没有锁冲突的呢？答案我们稍微考虑下就知道了，表的意向锁肯定不能够判断出来的，最终还是要到那一行中去判断有没有冲突。所以网上经常说的提高了判断锁冲突的效率，这样我并不能理解。或者说，其实是加了IX锁，这样才可能提高效率，但是我理解IX锁会影响其他事务的写入，难道实我理解不对？？？这里我先记录下来。</p><h3 id="锁的实现方式"><a href="#锁的实现方式" class="headerlink" title="锁的实现方式"></a>锁的实现方式</h3><p>InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。</p><p>由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。  </p><p>当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。如果不同的索引碰巧都落到了同一个行上，那么同样会阻塞。  </p><p>即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。</p><p>这里我做一下补充，InnoDB给某一行数据加锁的时候，肯定是给所有能定位到这行数据的所有索引项加锁的，不然同一行数据，根据不同的索引查找到的话，锁就不能生效了。比如说，一个事务根据id更新，另一个事务根据索引更新。</p><p>另外感谢下原作者<a href="https://www.jianshu.com/p/fa28035656a9" target="_blank" rel="noopener">https://www.jianshu.com/p/fa28035656a9</a>、<a href="https://www.jianshu.com/p/325a492a859b" target="_blank" rel="noopener">https://www.jianshu.com/p/325a492a859b</a>。我只是看他们的文章过程中，产生了兴趣和思考。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2018/09/30/2018-9/mysql%20lock/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
