<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>永远的万事屋</title>
    <link>http://yoursite.com/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>做海贼王的油腻男人</description>
    <pubDate>Thu, 04 Jun 2020 08:23:34 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>https与非对称加密</title>
      <link>http://yoursite.com/2020/06/03/2020-6/Https%E4%B8%8E%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86/</link>
      <guid>http://yoursite.com/2020/06/03/2020-6/Https%E4%B8%8E%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86/</guid>
      <pubDate>Wed, 03 Jun 2020 09:44:52 GMT</pubDate>
      <description>
      
        &lt;h2 id=&quot;背景描述&quot;&gt;&lt;a href=&quot;#背景描述&quot; class=&quot;headerlink&quot; title=&quot;背景描述&quot;&gt;&lt;/a&gt;背景描述&lt;/h2&gt;&lt;p&gt;一直对https一知半解，看过不少的文章，看的时候觉得别人说的头头是道，但脱离了别人的文章到自己身上的时候又什么都说不出，所以决定自己尝试写写，看能不能写出点理解。&lt;/p&gt;
&lt;h2 id=&quot;纠正认知&quot;&gt;&lt;a href=&quot;#纠正认知&quot; class=&quot;headerlink&quot; title=&quot;纠正认知&quot;&gt;&lt;/a&gt;纠正认知&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;http://chuantu.xyz/t6/738/1591178176x2073446431.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;上图是我参考别人的文章梳理出的知识点，红线标记出来的是我之前的疑惑点，从我上学开始有句话就一直记在我心里：公钥加密，私钥解密。也就是这句话一直造成了我的错误理解：&lt;strong&gt;公钥只能用于加密，私钥只能用于解密&lt;/strong&gt;。基于这个错误的认知去理解https，就造成了我对https的理解困难。&lt;/p&gt;
&lt;p&gt;其实公钥与私钥是成对的，成对的意思是：&lt;strong&gt;公钥加密私钥才能解密，私钥加密公钥才能解密&lt;/strong&gt;，并且公钥与私钥都可以加密或者解密，它俩唯一的区别就是：公钥是公开的，私钥是私有的。应用它俩的这种特性的技术场景就是：数据加密、数字签名。&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><p>一直对https一知半解，看过不少的文章，看的时候觉得别人说的头头是道，但脱离了别人的文章到自己身上的时候又什么都说不出，所以决定自己尝试写写，看能不能写出点理解。</p><h2 id="纠正认知"><a href="#纠正认知" class="headerlink" title="纠正认知"></a>纠正认知</h2><p><img src="http://chuantu.xyz/t6/738/1591178176x2073446431.png" alt=""><br>上图是我参考别人的文章梳理出的知识点，红线标记出来的是我之前的疑惑点，从我上学开始有句话就一直记在我心里：公钥加密，私钥解密。也就是这句话一直造成了我的错误理解：<strong>公钥只能用于加密，私钥只能用于解密</strong>。基于这个错误的认知去理解https，就造成了我对https的理解困难。</p><p>其实公钥与私钥是成对的，成对的意思是：<strong>公钥加密私钥才能解密，私钥加密公钥才能解密</strong>，并且公钥与私钥都可以加密或者解密，它俩唯一的区别就是：公钥是公开的，私钥是私有的。应用它俩的这种特性的技术场景就是：数据加密、数字签名。</p><a id="more"></a><h2 id="场景验证"><a href="#场景验证" class="headerlink" title="场景验证"></a>场景验证</h2><p>目前我们的网络是如下图所示的，在到达我们真正要到达的服务器之间是需要经过很多代理的，无论是正常的一二级网络运营商或者是黑客侵入我们的客户端对网络的劫持，我们的数据都是可能要经过网络代理层的，所以黑客很容易获取到客户端请求以及服务端响应的数据，下面我们从黑客攻击的场景描述https是如何做到信息安全的。<br><img src="http://chuantu.xyz/t6/738/1591186694x3703728804.png" alt=""></p><h3 id="信息泄露"><a href="#信息泄露" class="headerlink" title="信息泄露"></a>信息泄露</h3><p>由于客户端很容易介于客服端与服务端之间，所以获取到其之间传输的数据很容易。针对这种情况，https采用的是混合加密的方式，对称加密加密内容，非对称加密加密公钥。</p><ol><li>浏览器生成一个随机数R，并使用网站公钥对R进行加密</li><li>浏览器将加密的R，以及以R为秘钥使用对称加密加密内容传送给服务器</li><li>服务器用自己的私钥解密得到R，以R为秘钥使用对称加密解密内容，获取浏览器请求内容</li><li>服务器处理完请求之后，将响应内容以R为秘钥使用对称加密加密内容，返回给浏览器  </li><li>浏览器以R为秘钥使用对称加密解密内容，获得服务器响应</li></ol><p>由于黑客并没有服务器的私钥，所以获取不到R，获取不到R就解析不了数据的明文，并且对称加密的R是请求发生时随机生成的，也保证了黑客不能根据传输的数据，反推出秘钥R。</p><h3 id="中间人劫持"><a href="#中间人劫持" class="headerlink" title="中间人劫持"></a>中间人劫持</h3><p>解决了信息泄露的问题，我们传输的数据是不能被黑客明文浏览了。但是还存在一种黑客攻击：黑客假装服务器与我们通信，我们的数据根本传输不到服务端，这也是最常见的黑客攻击手段。<br><img src="http://chuantu.xyz/t6/738/1591189478x3661913030.png" alt=""><br>前面我们说客户端获取到了服务端的公钥，但是假如客户端获取的这个公钥已经是黑客的公钥了呢？这个黑客就能一直与客户端通信，黑客使用自己的私钥就能获取到了明文内容，而客户端还一直认为自己在和服务端通信。所以针对这种情况，https采用数字签名技术来解决，数字签名采用非对称加密技术与数字摘要技术的应用。存在一种权威的CA认证机构，此机构里存储了服务端提交给它的服务器公钥以及域名等其他信息生成的数字证书，此数字证书经过CA机构的私钥签名（hash+私钥加密）。  </p><p>所以https请求有一个证书认证的阶段，客户端发送服务器证书的请求，返回CA的证书。然后客户端收到证书后用本地操作系统内置证书上的公钥解密，如果能解开并且验证签名解开的hash内容与证书信息内容的hash一致，就证明证书是合法的，进而证明公钥确实是服务端的公钥。如果黑客返回的是自己的证书，是不能通过验证的，客户端就能发现自己的请求被劫持了。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2020/06/03/2020-6/Https%E4%B8%8E%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86/#disqus_thread</comments>
    </item>
    
    <item>
      <title>记一次数据库链接异常处理</title>
      <link>http://yoursite.com/2019/10/18/2019-10/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E9%93%BE%E6%8E%A5%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</link>
      <guid>http://yoursite.com/2019/10/18/2019-10/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E9%93%BE%E6%8E%A5%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</guid>
      <pubDate>Fri, 18 Oct 2019 08:14:52 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;背景描述&quot;&gt;&lt;a href=&quot;#背景描述&quot; class=&quot;headerlink&quot; title=&quot;背景描述&quot;&gt;&lt;/a&gt;背景描述&lt;/h2&gt;&lt;p&gt;公司大力推行docker，我们原有的物理机数据库都要求迁移到公司的弹性数据库。我们原以为只是简单的修改一下数据库链接，然而并
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="背景描述"><a href="#背景描述" class="headerlink" title="背景描述"></a>背景描述</h2><p>公司大力推行docker，我们原有的物理机数据库都要求迁移到公司的弹性数据库。我们原以为只是简单的修改一下数据库链接，然而并不是，第二天就有了线上问题。</p><h2 id="抛出的异常"><a href="#抛出的异常" class="headerlink" title="抛出的异常"></a>抛出的异常</h2><p><code>com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure</code><br>cause by:<br><code>Can not read response from server. Expected to read 4 bytes, read 0 bytes before connection was unexpectedly lost</code></p><h2 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h2><p>看异常的原因是因为，使用了失效的数据库链接。这个时候我们首先想到的是数据库连接池的配置有问题，然后我又充分了解了链接池配置的参数：<br><img src="https://i.imgur.com/HaO5CPk.png" alt=""><br>喽了一篇我们的链接池配置，testOnBorrow设置的为false，所以果断改成了true，然后再上线。<br>可惜报错！<br>然后我们再看报错异常，发现报出异常显示我们使用的是tomcat连接池？？我们一直以为自己使用的是DBCP？？这里先说一下我们的应用的技术环境：我们使用的Springboot1框架。所以我就去查了下，springboot1默认连接池是什么？没有在网上找到有人说这个事情，但是找到了所谓的可以指定配置连接池的方法。设置参数：<br><code>spring.datasource.type=org.apache.commons.dbcp2.BasicDataSource</code><br>然后我又去上线了。<br>可惜还是报错！<br>然后我就怀疑人生了，难道我写的有问题？所以我决定去撸源码，看springboot是如何指定数据源的，看到了如下代码：</p><pre><code>@SuppressWarnings(&quot;unchecked&quot;)public Class&lt;? extends DataSource&gt; findType() {    if (this.type != null) {        return this.type;    }    for (String name : DATA_SOURCE_TYPE_NAMES) {        try {            return (Class&lt;? extends DataSource&gt;) ClassUtils.forName(name,                    this.classLoader);        }        catch (Exception ex) {            // Swallow and continue        }    }    return null;}private static final String[] DATA_SOURCE_TYPE_NAMES = new String[] {        &quot;org.apache.tomcat.jdbc.pool.DataSource&quot;,        &quot;com.zaxxer.hikari.HikariDataSource&quot;,        &quot;org.apache.commons.dbcp.BasicDataSource&quot;, // deprecated        &quot;org.apache.commons.dbcp2.BasicDataSource&quot; };</code></pre><p>可以看到遍历数组，第一个元素为jdbc.pool，问题是并没有找到关于<strong>spring.datasource.type=org.apache.commons.dbcp2.BasicDataSource</strong>的配置！！！不知道网上的文章是哪里抄来的，而且真的很误导人。后来找到了如下正确的配置方式：<br><code>DataSourceBuilder.create().type(org.apache.commons.dbcp2.BasicDataSource.class).build()</code><br>然我再次上线，但是发现还是报错！！</p><h2 id="公司特殊环境"><a href="#公司特殊环境" class="headerlink" title="公司特殊环境"></a>公司特殊环境</h2><p>上述我也说了，我们接入的是公司<strong>弹性数据库</strong>。所谓弹性数据库，是在传统数据库基础上应用了docker容器化技术，做的一种可自动调整的数据库服务。简单原理如下图所示：<br><img src="https://i.imgur.com/AAkVgJK.png" alt=""><br>可以看到它是增加了一层数据库网关的，我们的应用连接的是数据库网关。到了这种时候我们只能找dba了，他让我们配置这两个参数：<br><code>socketTimeout=20000&amp;connectTimeout=10000</code>，我在网上查了查这些参数的含义：<br>connectTimeout：表示的是数据库驱动(mysql-connector-java)与mysql服务器建立TCP连接的超时时间。<br>socketTimeout：是通过TCP连接发送数据(在这里就是要执行的sql)后，等待响应的超时时间。<br>我其实抱着怀疑的态度配置上的，因为我认为这两个参数和我的连接失效并没有关系。但是我上线后，居然没有再报错了！！！我去询问dba原因，他也说不出个所以然来（大公司基本都这样）。我个人怀疑他们的网关层，应该是根据这个机制做了什么事情，但是具体做了什么，我也就不清楚了。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/10/18/2019-10/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E9%93%BE%E6%8E%A5%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/#disqus_thread</comments>
    </item>
    
    <item>
      <title>从零手撸RPC</title>
      <link>http://yoursite.com/2019/10/15/2019-10/%E4%BB%8E%E9%9B%B6%E6%89%8B%E6%92%B8RPC/</link>
      <guid>http://yoursite.com/2019/10/15/2019-10/%E4%BB%8E%E9%9B%B6%E6%89%8B%E6%92%B8RPC/</guid>
      <pubDate>Tue, 15 Oct 2019 11:55:23 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;先了解下什么是RPC&quot;&gt;&lt;a href=&quot;#先了解下什么是RPC&quot; class=&quot;headerlink&quot; title=&quot;先了解下什么是RPC&quot;&gt;&lt;/a&gt;先了解下什么是RPC&lt;/h1&gt;&lt;p&gt;随着互联网的发展，我们的系统不再只是一些简单的数据存储，承载了越来越多的现实
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="先了解下什么是RPC"><a href="#先了解下什么是RPC" class="headerlink" title="先了解下什么是RPC"></a>先了解下什么是RPC</h1><p>随着互联网的发展，我们的系统不再只是一些简单的数据存储，承载了越来越多的现实中的业务，随之而来的是，我们系统也越来越复杂，一个单独的应用已经不能在承载全部的业务，所以需要把业务进行拆分，根据不同的业务域拆分出不同的业务系统。问题随之而来，不在一个应用后，原来写在一起的代码拆分到多个应用，他们之间该如何调用呢？为了解决这个问题，RPC应运而生。</p><h1 id="RPC的核心模块"><a href="#RPC的核心模块" class="headerlink" title="RPC的核心模块"></a>RPC的核心模块</h1><p>动态代理、序列化、协议、通讯、注册中心</p><h2 id="动态代理"><a href="#动态代理" class="headerlink" title="动态代理"></a>动态代理</h2><p>代理模式上，基本上有Subject角色，RealSubject角色，Proxy角色。其中：Subject角色负责定义RealSubject和Proxy角色应该实现的接口；RealSubject角色用来真正完成业务服务功能；Proxy角色负责将自身的Request请求，调用realsubject 对应的request功能来实现业务功能，自己不真正做业务。<br>代理模式，凸显出来的是<strong>“代理”</strong>二字，必然存在一个Proxy类。如果这个Proxy类是自己手写的class，被称为静态代理；如果这个Proxy类是代码生成的class，被称为动态代理。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/10/15/2019-10/%E4%BB%8E%E9%9B%B6%E6%89%8B%E6%92%B8RPC/#disqus_thread</comments>
    </item>
    
    <item>
      <title>内存淘汰算法</title>
      <link>http://yoursite.com/2019/09/25/2019-9/%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95/</link>
      <guid>http://yoursite.com/2019/09/25/2019-9/%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95/</guid>
      <pubDate>Wed, 25 Sep 2019 12:40:36 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;为什么需要淘汰数据&quot;&gt;&lt;a href=&quot;#为什么需要淘汰数据&quot; class=&quot;headerlink&quot; title=&quot;为什么需要淘汰数据&quot;&gt;&lt;/a&gt;为什么需要淘汰数据&lt;/h2&gt;&lt;p&gt;存储是有限的，而数据是无限的，我们要以有限的存储，来获取最大的价值。查询一个数据，这
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="为什么需要淘汰数据"><a href="#为什么需要淘汰数据" class="headerlink" title="为什么需要淘汰数据"></a>为什么需要淘汰数据</h2><p>存储是有限的，而数据是无限的，我们要以有限的存储，来获取最大的价值。查询一个数据，这个数据刚好在缓存中，我们称为命中缓存。<strong>命中率</strong>是衡量一个缓存的重要指标。下面讲一下几种常见的淘汰算法。</p><h2 id="FIFO（先进先出：First-in-First-out）"><a href="#FIFO（先进先出：First-in-First-out）" class="headerlink" title="FIFO（先进先出：First-in,First-out）"></a>FIFO（先进先出：First-in,First-out）</h2><p>###算法思想<br>数据结构：单向队列<br>向队列尾部添加元素，内存满了的时候，从队列头部淘汰元素。</p><p>###算法缺陷<br>每个元素都是平等对待，无论此元素是否访问很频繁，命中率很低。</p><p>###算法优势<br>实现简单。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/09/25/2019-9/%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95/#disqus_thread</comments>
    </item>
    
    <item>
      <title>HashMap的小认识</title>
      <link>http://yoursite.com/2019/09/23/2019-9/HashMap%E7%9A%84%E5%B0%8F%E8%AE%A4%E8%AF%86/</link>
      <guid>http://yoursite.com/2019/09/23/2019-9/HashMap%E7%9A%84%E5%B0%8F%E8%AE%A4%E8%AF%86/</guid>
      <pubDate>Mon, 23 Sep 2019 10:21:36 GMT</pubDate>
      <description>
      
        &lt;p&gt;想充分了解HashMap很久了，这个我们时刻使用，但是对于我来说总感觉有着迷雾的数据结构。  &lt;/p&gt;
&lt;p&gt;##HashMap&lt;br&gt;下面是居于JDK7的，JDK8的红黑树结构暂时放弃。  &lt;/p&gt;
&lt;h3 id=&quot;数据结构&quot;&gt;&lt;a href=&quot;#数据结构&quot; class=&quot;headerlink&quot; title=&quot;数据结构&quot;&gt;&lt;/a&gt;数据结构&lt;/h3&gt;&lt;p&gt;HashMap继承了AbstractMap、实现了Map&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class HashMap&amp;lt;K,V&amp;gt;
extends AbstractMap&amp;lt;K,V&amp;gt;
implements Map&amp;lt;K,V&amp;gt;, Cloneable, Serializable
{
/**
 * The table, resized as necessary. Length MUST Always be a power of two.
 */
transient Entry&amp;lt;K,V&amp;gt;[] table;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重要的是数组table以及它的内部类Entry。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;static class Entry&amp;lt;K,V&amp;gt; implements Map.Entry&amp;lt;K,V&amp;gt; {
    final K key;
    V value;
    Entry&amp;lt;K,V&amp;gt; next;
    int hash;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到Entry里有一个next属性，所以它本身就是个单链表，以下就是我们常说的数组+链表的结构：  &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/4843132-05b3a55bd2686dd3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>想充分了解HashMap很久了，这个我们时刻使用，但是对于我来说总感觉有着迷雾的数据结构。  </p><p>##HashMap<br>下面是居于JDK7的，JDK8的红黑树结构暂时放弃。  </p><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>HashMap继承了AbstractMap、实现了Map</p><pre><code>public class HashMap&lt;K,V&gt;extends AbstractMap&lt;K,V&gt;implements Map&lt;K,V&gt;, Cloneable, Serializable{/** * The table, resized as necessary. Length MUST Always be a power of two. */transient Entry&lt;K,V&gt;[] table;</code></pre><p>重要的是数组table以及它的内部类Entry。  </p><pre><code>static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {    final K key;    V value;    Entry&lt;K,V&gt; next;    int hash;</code></pre><p>可以看到Entry里有一个next属性，所以它本身就是个单链表，以下就是我们常说的数组+链表的结构：  </p><p><img src="https://upload-images.jianshu.io/upload_images/4843132-05b3a55bd2686dd3.png" alt=""></p><a id="more"></a><h3 id="put方法"><a href="#put方法" class="headerlink" title="put方法"></a>put方法</h3><p>代码还是很简单的，稍微一看都能清楚：  </p><pre><code>public V put(K key, V value) {       // 对key为null的处理       if (key == null)           return putForNullKey(value);       // 根据key算出hash值       int hash = hash(key);       // 根据hash值和HashMap容量算出在table中应该存储的下标i       int i = indexFor(hash, table.length);       for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) {           Object k;           // 先判断hash值是否一样，如果一样，再判断key是否一样           if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) {               V oldValue = e.value;               e.value = value;               e.recordAccess(this);               return oldValue;           }       }       modCount++;       addEntry(hash, key, value, i);       return null;   }</code></pre><p>整理出来的流程图如下：<br><img src="https://upload-images.jianshu.io/upload_images/4843132-3d5e78f87bb64216.png" alt=""><br>值得注意点的地方是：   </p><pre><code>static int indexFor(int h, int length) {    return h &amp; (length-1);}</code></pre><p>可以看到是用&amp;的位运算，&amp;运算是CPU的运算方式，所以效率是杠杠的，至于为什么是跟length-1进行&amp;的位运呢？<br>因为length为2的幂次方，即一定是偶数，偶数减1，即是奇数，这样保证了（length-1）在二进制中最低位是1，而&amp;运算结果的最低位是1还是0完全取决于hash值二进制的最低位。如果length为奇数，则length-1则为偶数，则length-1二进制的最低位横为0，则&amp;位运算的结果最低位横为0，即横为偶数。这样table数组就只可能在偶数下标的位置存储了数据，浪费了所有奇数下标的位置，这样也更容易产生hash冲突。<strong>这也是HashMap的容量为什么总是2的平方数的原因。</strong><br><img src="https://upload-images.jianshu.io/upload_images/4843132-91b165309b5d447c.png" alt=""></p><h3 id="resize、get"><a href="#resize、get" class="headerlink" title="resize、get"></a>resize、get</h3><p>这个的流程和put类似，都是先计算hash值以及对应的index下表，然后重新赋值或者获取元素，这里就不在啰嗦。</p><h3 id="iterate"><a href="#iterate" class="headerlink" title="iterate"></a>iterate</h3><p>这里我了解下，为什么map的遍历不是有序的，以及它是如何做的。<br>核心代码如下：  </p><pre><code>final Entry&lt;K,V&gt; nextEntry() {    // 保存下一个需要返回的Entry，作为返回结果    Entry&lt;K,V&gt; e = next;    // 如果遍历到table上单向链表的最后一个元素时    if ((next = e.next) == null) {        Entry[] t = table;        // 继续往下寻找table上有元素的下标        // 并且把下一个talbe上有单向链表的表头，作为下一个返回的Entry next        while (index &lt; t.length &amp;&amp; (next = t[index++]) == null)            ;    }    current = e;    return e;}</code></pre><p>nextEntry的主要作用有两点</p><ol><li>把当前遍历到的Entry返回</li><li>准备好下一个需要返回的Entry  </li></ol><p>如果当前返回的Entry不是单向链表的最后一个元素，那只要让下一个返回的Entrynext为当前Entry的next属性（下图红色过程）；如果当前返回的Entry是单向链表的最后一个元素，那么它就没有next属性了，所以要寻找下一个table上有单向链表的表头（下图绿色过程）<br><img src="https://upload-images.jianshu.io/upload_images/4843132-3830a9227f7df10f.png" alt="">  </p><p>##LinkedHashMap<br>LinkedHashMap是在HashMap的基础上又维护了Entry之间的一个双向链表，其结构如下图所示：<br><img src="https://upload-images.jianshu.io/upload_images/4843132-7abca1abd714341d.png" alt="">  </p><pre><code>private static class Entry&lt;K,V&gt; extends HashMap.Entry&lt;K,V&gt; {    // These fields comprise the doubly linked list used for iteration.    Entry&lt;K,V&gt; before, after;    Entry(int hash, K key, V value, HashMap.Entry&lt;K,V&gt; next) {        super(hash, key, value, next);    }</code></pre><p>可以到相比HashMap.Entry，LinkedHashMap.Entry多了before和after，这就是用来维护双向链表的。</p><h3 id="put方法-1"><a href="#put方法-1" class="headerlink" title="put方法"></a>put方法</h3><p>新加入的元素维护到双向链表的末尾，代码如下：  </p><pre><code>private void addBefore(Entry&lt;K,V&gt; existingEntry) {    after  = existingEntry;    before = existingEntry.before;    before.after = this;    after.before = this;}</code></pre><h3 id="iterate-1"><a href="#iterate-1" class="headerlink" title="iterate"></a>iterate</h3><p>从双向链表表头的第一个元素开始，遍历效率是大于HashMap的。</p><h3 id="重排序"><a href="#重排序" class="headerlink" title="重排序"></a>重排序</h3><p>LinkedHashMap有一个比较特殊的构造函数：  </p><pre><code>public LinkedHashMap(int initialCapacity,                     float loadFactor,                     boolean accessOrder) {    super(initialCapacity, loadFactor);    this.accessOrder = accessOrder;}</code></pre><p>accessOrder默认为false，标识元素顺序与插入顺序相关；如果为true，标识元素顺序与访问顺序相关。能做到这点，就是因为在accessOrder=true的情况下，每一次访问都会将元素重新排序：  </p><pre><code>void recordAccess(HashMap&lt;K,V&gt; m) {    LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m;    // 如果LinkedHashMap的accessOrder为true，则进行重排序    // 比如前面提到LruCache中使用到的LinkedHashMap的accessOrder属性就为true    if (lm.accessOrder) {        lm.modCount++;        // 把更新的Entry从双向链表中移除        remove();        // 再把更新的Entry加入到双向链表的表尾        addBefore(lm.header);    }}</code></pre><p>其实到这里我就比较好奇了，根据插入顺序的HashMap还有一些场景，但是每次读顺序都会改变的HashMap有哪些使用场景呢？</p><!-- more --><h2 id="LinkedHashMap与LRU"><a href="#LinkedHashMap与LRU" class="headerlink" title="LinkedHashMap与LRU"></a>LinkedHashMap与LRU</h2><p>每次访问的元素都会被放置在队列末尾，这和LRU（Least Recently Used最近最少算法）算法的特性是一致的。所以我们利用这个特性，能很轻易实现LRU-1算法，事实上java本身也给我们留好了实现的接口：  </p><pre><code>protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) {    return false;}</code></pre><p>我们只要覆盖这个方法就是一个线程不安全的LRU了。<br>LRU本身是内存淘汰算法，关于这个请听下回分解。</p>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/09/23/2019-9/HashMap%E7%9A%84%E5%B0%8F%E8%AE%A4%E8%AF%86/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
